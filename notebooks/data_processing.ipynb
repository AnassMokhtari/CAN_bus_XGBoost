{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAN Bus Data Processing\n",
    "\n",
    "This notebook processes a CAN bus log file (`full_data_capture.log`) to generate a dataset optimized for predictive maintenance and attack detection (DoS, Fuzzing, Suspension) using XGBoost. It performs the following steps:\n",
    "\n",
    "1. **Import Libraries**: Load required Python libraries.\n",
    "2. **Define Functions**: Define helper functions for parsing, attack injection, feature computation, and CSV output.\n",
    "3. **Process Data**: Read the log file, inject distinct attack patterns, compute enhanced features, label messages, and save to CSV.\n",
    "\n",
    "**Input File**: `C:\\Users\\pc\\OneDrive\\Bureau\\VS_code_Projects\\MLproject_Predictive_Maintenance_for_Vehicles_Using_CAN_Bus_Data\\dataSet\\raw\\full_data_capture.log`\n",
    "\n",
    "**Output File**: `C:\\Users\\pc\\OneDrive\\Bureau\\VS_code_Projects\\MLproject_Predictive_Maintenance_for_Vehicles_Using_CAN_Bus_Data\\dataSet\\processed\\generated.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "Import libraries for file handling, data processing, feature computation, and progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Functions\n",
    "\n",
    "Define helper functions for:\n",
    "- Converting the CAN log to CSV.\n",
    "- Computing features (`CAN_ID_Inter_Arrival`, `CAN_ID_Window_Count`, `Payload_Entropy`, etc.).\n",
    "- Injecting attacks (DoS, Fuzzing, Suspension) with distinct patterns.\n",
    "- Labeling messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_payload(length=16):\n",
    "    \"\"\"Generate a random hexadecimal payload of specified length.\"\"\"\n",
    "    return ''.join(random.choice(string.hexdigits.upper()) for _ in range(length))\n",
    "\n",
    "def convert_can_log_to_csv(input_file_path, output_file_path):\n",
    "    # Verify input file exists\n",
    "    if not Path(input_file_path).is_file():\n",
    "        print(f\"Error: Input file '{input_file_path}' does not exist.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    output_dir = Path(output_file_path).parent\n",
    "    try:\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating output directory '{output_dir}': {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Step 1: Read messages with progress\n",
    "    messages = []\n",
    "    total_lines = sum(1 for _ in open(input_file_path, 'r', encoding='utf-8'))\n",
    "    print(f\"Reading input file with {total_lines} lines...\")\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as log_file:\n",
    "        for line in tqdm(log_file, total=total_lines, desc=\"Parsing lines\"):\n",
    "            line = line.strip()\n",
    "            if not line or not line.startswith('('):\n",
    "                continue\n",
    "            try:\n",
    "                timestamp_end = line.find(')')\n",
    "                timestamp = float(line[1:timestamp_end])\n",
    "                remaining = line[timestamp_end+1:].strip()\n",
    "                parts = remaining.split(maxsplit=1)\n",
    "                if len(parts) == 2:\n",
    "                    interface = parts[0]\n",
    "                    can_data = parts[1]\n",
    "                    if '#' in can_data:\n",
    "                        can_id, payload = can_data.split('#', 1)\n",
    "                        messages.append({\n",
    "                            'Timestamp': timestamp,\n",
    "                            'Interface': interface,\n",
    "                            'CAN_ID': can_id,\n",
    "                            'Payload': payload\n",
    "                        })\n",
    "            except:\n",
    "                continue\n",
    "    if not messages:\n",
    "        print(\"No valid messages found in the log file.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(messages)\n",
    "    print(f\"Loaded {len(df)} messages into DataFrame.\")\n",
    "\n",
    "    # Debug: Check 2C6 messages\n",
    "    c2c6_count = len(df[df['CAN_ID'] == '2C6'])\n",
    "    print(f\"Debug: Total CAN_ID=2C6 messages: {c2c6_count}\")\n",
    "    if c2c6_count < 2222:\n",
    "        print(f\"Warning: Only {c2c6_count} CAN_ID=2C6 messages found. Suspension attack may be limited.\")\n",
    "\n",
    "    # Step 2: Inject DoS attack\n",
    "    dos_start = 1508687520.000000\n",
    "    dos_end = 1508687529.999750\n",
    "    dos_interval = 0.00025  # 4 packets/ms\n",
    "    dos_timestamps = np.arange(dos_start, dos_end + dos_interval, dos_interval)[:40001]\n",
    "    dos_df = pd.DataFrame({\n",
    "        'Timestamp': dos_timestamps,\n",
    "        'Interface': 'slcan0',\n",
    "        'CAN_ID': '000',\n",
    "        'Payload': '0000000000000000'\n",
    "    })\n",
    "    df = df[~df['Timestamp'].between(dos_start, dos_end)]\n",
    "    df = pd.concat([df, dos_df], ignore_index=True)\n",
    "    print(f\"Injected DoS attack: {len(dos_df)} messages.\")\n",
    "\n",
    "    # Step 3: Inject Fuzzing attack\n",
    "    fuzzing_start = 1508687510.000000\n",
    "    fuzzing_end = 1508687515.999500\n",
    "    fuzzing_messages = df[(df['CAN_ID'] == '18A') & (df['Timestamp'].between(fuzzing_start, fuzzing_end))].head(2222)\n",
    "    if len(fuzzing_messages) < 2222:\n",
    "        print(f\"Warning: Only {len(fuzzing_messages)} messages available for CAN_ID=18A for fuzzing.\")\n",
    "        # Supplement with synthetic fuzzing messages if needed\n",
    "        additional_needed = 2222 - len(fuzzing_messages)\n",
    "        fuzzing_timestamps = np.linspace(fuzzing_start, fuzzing_end, additional_needed)\n",
    "        additional_fuzzing = pd.DataFrame({\n",
    "            'Timestamp': fuzzing_timestamps,\n",
    "            'Interface': 'slcan0',\n",
    "            'CAN_ID': '18A',\n",
    "            'Payload': [generate_random_payload() for _ in range(additional_needed)]\n",
    "        })\n",
    "        df = pd.concat([df, additional_fuzzing], ignore_index=True)\n",
    "        print(f\"Added {additional_needed} synthetic fuzzing messages.\")\n",
    "    else:\n",
    "        fuzzing_indices = fuzzing_messages.index\n",
    "        df.loc[fuzzing_indices, 'Payload'] = [generate_random_payload() for _ in fuzzing_indices]\n",
    "    print(f\"Injected Fuzzing attack: {2222} messages.\")\n",
    "\n",
    "    # Step 4: Inject Suspension attack\n",
    "    suspension_start = 1508687486.000000\n",
    "    suspension_end = 1508687506.000000  # Extended to 20s\n",
    "    c2c6_deleted = len(df[(df['CAN_ID'] == '2C6') & (df['Timestamp'].between(suspension_start, suspension_end))])\n",
    "    print(f\"Debug: Deleted {c2c6_deleted} CAN_ID=2C6 messages in Suspension period.\")\n",
    "    df = df[~((df['CAN_ID'] == '2C6') & (df['Timestamp'].between(suspension_start, suspension_end)))]\n",
    "    print(f\"After Suspension attack: {len(df)} messages remain.\")\n",
    "\n",
    "    # Step 5: Compute parameters\n",
    "    df = df.sort_values('Timestamp').reset_index(drop=True)\n",
    "\n",
    "    # CAN_ID_Inter_Arrival\n",
    "    df['CAN_ID_Inter_Arrival'] = df.groupby('CAN_ID')['Timestamp'].diff().fillna(0.010)\n",
    "    print(\"Computed CAN_ID_Inter_Arrival.\")\n",
    "\n",
    "    # CAN_ID_Window_Count\n",
    "    def compute_window_count(df, window_size=5.0):\n",
    "        print(f\"Computing CAN_ID_Window_Count for {len(df)} messages...\")\n",
    "        df = df.copy()\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "        window_counts = []\n",
    "        for can_id in tqdm(df['CAN_ID'].unique(), desc=\"Processing CAN_IDs\"):\n",
    "            can_id_df = df[df['CAN_ID'] == can_id][['Timestamp']].copy()\n",
    "            can_id_df['Dummy'] = 1\n",
    "            can_id_df.set_index('Timestamp', inplace=True)\n",
    "            can_id_df['CAN_ID_Window_Count'] = (\n",
    "                can_id_df['Dummy']\n",
    "                .rolling(window=f'{window_size}s', closed='both')\n",
    "                .count()\n",
    "                .astype(int)\n",
    "            )\n",
    "            can_id_df.reset_index(inplace=True)\n",
    "            can_id_df['CAN_ID'] = can_id\n",
    "            window_counts.append(can_id_df[['Timestamp', 'CAN_ID', 'CAN_ID_Window_Count']])\n",
    "        result = pd.concat(window_counts)\n",
    "        result['Timestamp'] = result['Timestamp'].astype(int) / 10**9\n",
    "        return result\n",
    "\n",
    "    window_counts = compute_window_count(df)\n",
    "    df = df.merge(window_counts, on=['Timestamp', 'CAN_ID'], how='left')\n",
    "    df['CAN_ID_Window_Count'] = df['CAN_ID_Window_Count'].fillna(0).astype(int)\n",
    "    print(f\"Debug: NaN in CAN_ID_Window_Count: {df['CAN_ID_Window_Count'].isna().sum()}\")\n",
    "    print(\"Computed CAN_ID_Window_Count.\")\n",
    "\n",
    "    # Payload_Entropy\n",
    "    def compute_payload_entropy(payload):\n",
    "        if not payload:\n",
    "            return 0.0\n",
    "        bytes_array = [int(payload[i:i+2], 16) for i in range(0, len(payload), 2)]\n",
    "        value_counts = pd.Series(bytes_array).value_counts()\n",
    "        probs = value_counts / len(bytes_array)\n",
    "        return entropy(probs, base=2)\n",
    "\n",
    "    df['Payload_Entropy'] = df['Payload'].apply(compute_payload_entropy)\n",
    "    print(\"Computed Payload_Entropy.\")\n",
    "\n",
    "    # Payload_Decimal\n",
    "    def compute_payload_decimal(payload):\n",
    "        try:\n",
    "            return int(payload, 16)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "\n",
    "    df['Payload_Decimal'] = df['Payload'].apply(compute_payload_decimal)\n",
    "    print(\"Computed Payload_Decimal.\")\n",
    "\n",
    "    # Norm_Payload_Decimal\n",
    "    max_decimal = 2**64 - 1\n",
    "    df['Norm_Payload_Decimal'] = df['Payload_Decimal'] / max_decimal\n",
    "    print(\"Computed Norm_Payload_Decimal.\")\n",
    "\n",
    "    # Norm_Payload_Entropy\n",
    "    max_entropy = 8.0\n",
    "    df['Norm_Payload_Entropy'] = df['Payload_Entropy'] / max_entropy\n",
    "    print(\"Computed Norm_Payload_Entropy.\")\n",
    "\n",
    "    # Suspension_Indicator\n",
    "    def compute_suspension_indicator(df, threshold=2.0, window=0.5):\n",
    "        print(f\"Computing Suspension_Indicator for {len(df)} messages...\")\n",
    "        df = df.sort_values('Timestamp')\n",
    "        indicators = np.zeros(len(df))\n",
    "        total_can_ids = len(df['CAN_ID'].unique())\n",
    "        timestamps = df['Timestamp'].to_numpy()\n",
    "        inter_arrivals = df['CAN_ID_Inter_Arrival'].to_numpy()\n",
    "        can_ids = df['CAN_ID'].to_numpy()\n",
    "        for i in tqdm(range(len(df)), desc=\"Processing messages\"):\n",
    "            timestamp = timestamps[i]\n",
    "            mask = (timestamps >= timestamp - window) & (timestamps <= timestamp + window) & (inter_arrivals > threshold)\n",
    "            affected_can_ids = len(np.unique(can_ids[mask]))\n",
    "            indicators[i] = affected_can_ids / total_can_ids if total_can_ids > 0 else 0.0\n",
    "        return indicators\n",
    "\n",
    "    df['Suspension_Indicator'] = compute_suspension_indicator(df)\n",
    "    print(\"Computed Suspension_Indicator.\")\n",
    "\n",
    "    # Debug: Check 2C6 messages post-Suspension\n",
    "    c2c6_post_suspension = df[(df['CAN_ID'] == '2C6') & (df['Timestamp'] >= suspension_end)]\n",
    "    print(f\"Debug: CAN_ID=2C6 messages after suspension_end ({suspension_end}): {len(c2c6_post_suspension)}\")\n",
    "    if not c2c6_post_suspension.empty:\n",
    "        print(\"Debug: First 5 CAN_ID=2C6 messages post-Suspension:\")\n",
    "        print(c2c6_post_suspension[['Timestamp', 'CAN_ID_Inter_Arrival', 'Suspension_Indicator', 'Payload_Entropy']].head())\n",
    "\n",
    "    # Compute normal statistics (excluding all attack periods)\n",
    "    normal_df = df[\n",
    "        ~(\n",
    "            (df['Timestamp'].between(dos_start, dos_end) & (df['CAN_ID'] == '000')) |  # DoS\n",
    "            (df['Timestamp'].between(fuzzing_start, fuzzing_end) & (df['CAN_ID'] == '18A')) |  # Fuzzing\n",
    "            (df['CAN_ID'] == '2C6') & (df['Timestamp'] >= suspension_end)  # Suspension\n",
    "        )\n",
    "    ]\n",
    "    normal_stats = normal_df.groupby('CAN_ID').agg({\n",
    "        'CAN_ID_Inter_Arrival': 'mean',\n",
    "        'CAN_ID_Window_Count': 'mean'\n",
    "    }).reset_index()\n",
    "    normal_stats.columns = ['CAN_ID', 'Mean_Inter_Arrival', 'Mean_Window_Count']\n",
    "    print(\"Computed normal statistics.\")\n",
    "\n",
    "    # Normalize Inter_Arrival and Window_Count\n",
    "    def normalize_features(row, stats_df):\n",
    "        can_id = row['CAN_ID']\n",
    "        stats = stats_df[stats_df['CAN_ID'] == can_id]\n",
    "        if not stats.empty:\n",
    "            norm_inter_arrival = row['CAN_ID_Inter_Arrival'] / stats['Mean_Inter_Arrival'].iloc[0] if stats['Mean_Inter_Arrival'].iloc[0] != 0 else 1.0\n",
    "            norm_window_count = row['CAN_ID_Window_Count'] / stats['Mean_Window_Count'].iloc[0] if stats['Mean_Window_Count'].iloc[0] != 0 else 1.0\n",
    "        else:\n",
    "            norm_inter_arrival = 1.0\n",
    "            norm_window_count = 1.0\n",
    "        return pd.Series({\n",
    "            'Norm_Inter_Arrival': norm_inter_arrival,\n",
    "            'Norm_Window_Count': norm_window_count\n",
    "        })\n",
    "\n",
    "    print(f\"Normalizing features for {len(df)} messages...\")\n",
    "    normalized_features = df.apply(normalize_features, axis=1, args=(normal_stats,))\n",
    "    df = pd.concat([df, normalized_features], axis=1)\n",
    "    print(\"Computed normalized features.\")\n",
    "\n",
    "    # Label attacks\n",
    "    df['Label'] = 0  # Normal\n",
    "    df.loc[df['Timestamp'].between(dos_start, dos_end) & (df['CAN_ID'] == '000'), 'Label'] = 1  # DoS\n",
    "    df.loc[df['Timestamp'].between(fuzzing_start, fuzzing_end) & (df['CAN_ID'] == '18A'), 'Label'] = 2  # Fuzzing\n",
    "    suspension_candidates = df[(df['CAN_ID'] == '2C6') & (df['Timestamp'] >= suspension_end)].head(2222)\n",
    "    if len(suspension_candidates) < 2222:\n",
    "        print(f\"Warning: Only {len(suspension_candidates)} CAN_ID=2C6 messages available post-suspension.\")\n",
    "        # Supplement with synthetic messages if needed\n",
    "        additional_needed = 2222 - len(suspension_candidates)\n",
    "        last_timestamp = suspension_candidates['Timestamp'].max() if not suspension_candidates.empty else suspension_end\n",
    "        synthetic_timestamps = np.linspace(last_timestamp + 0.001, last_timestamp + additional_needed * 0.010, additional_needed)\n",
    "        synthetic_suspension = pd.DataFrame({\n",
    "            'Timestamp': synthetic_timestamps,\n",
    "            'Interface': 'slcan0',\n",
    "            'CAN_ID': '2C6',\n",
    "            'Payload': ['0000000000000000' for _ in range(additional_needed)],\n",
    "            'CAN_ID_Inter_Arrival': [10.0 for _ in range(additional_needed)],  # Simulate large inter-arrival\n",
    "            'CAN_ID_Window_Count': [1 for _ in range(additional_needed)],\n",
    "            'Payload_Entropy': [0.0 for _ in range(additional_needed)],\n",
    "            'Payload_Decimal': [0 for _ in range(additional_needed)],\n",
    "            'Norm_Payload_Decimal': [0.0 for _ in range(additional_needed)],\n",
    "            'Norm_Payload_Entropy': [0.0 for _ in range(additional_needed)],\n",
    "            'Suspension_Indicator': [1.0 for _ in range(additional_needed)],\n",
    "            'Norm_Inter_Arrival': [100.0 for _ in range(additional_needed)],  # High normalized value\n",
    "            'Norm_Window_Count': [0.1 for _ in range(additional_needed)],\n",
    "            'Label': [3 for _ in range(additional_needed)]\n",
    "        })\n",
    "        df = pd.concat([df, synthetic_suspension], ignore_index=True)\n",
    "        print(f\"Added {additional_needed} synthetic suspension messages.\")\n",
    "    else:\n",
    "        df.loc[suspension_candidates.index, 'Label'] = 3  # Suspension\n",
    "    print(f\"Labeled {2222} Suspension messages.\")\n",
    "\n",
    "    # Debug: Feature distributions by label\n",
    "    print(\"\\nFeature Distributions by Label:\")\n",
    "    for label in range(4):\n",
    "        label_df = df[df['Label'] == label]\n",
    "        print(f\"Label {label} ({['Normal', 'DoS', 'Fuzzing', 'Suspension'][label]}):\")\n",
    "        print(label_df[['CAN_ID_Inter_Arrival', 'CAN_ID_Window_Count', 'Payload_Entropy', 'Suspension_Indicator']].describe())\n",
    "\n",
    "    # Step 6: Write to CSV with progress\n",
    "    print(f\"Writing {len(df)} rows to CSV...\")\n",
    "    try:\n",
    "        if Path(output_file_path).exists():\n",
    "            try:\n",
    "                with open(output_file_path, 'a') as test_file:\n",
    "                    pass\n",
    "            except PermissionError:\n",
    "                print(f\"Warning: Output file '{output_file_path}' may be read-only.\")\n",
    "                print(\"Suggestions:\")\n",
    "                print(\"- Close applications using the file (e.g., Excel).\")\n",
    "                print(\"- Pause OneDrive sync temporarily.\")\n",
    "                print(\"- Delete or rename the existing file.\")\n",
    "                print(\"- Check file permissions (Properties > Security).\")\n",
    "                print(\"- Use an alternative output path (e.g., 'C:\\\\Temp').\")\n",
    "\n",
    "        with open(output_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.writer(csv_file, quoting=csv.QUOTE_MINIMAL, escapechar='\\\\')\n",
    "            writer.writerow([\n",
    "                'Timestamp', 'Interface', 'CAN_ID', 'Payload', 'CAN_ID_Inter_Arrival',\n",
    "                'CAN_ID_Window_Count', 'Payload_Entropy', 'Norm_Inter_Arrival',\n",
    "                'Norm_Window_Count', 'Norm_Payload_Entropy', 'Norm_Payload_Decimal',\n",
    "                'Suspension_Indicator', 'Label'\n",
    "            ])\n",
    "            for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Writing CSV rows\"):\n",
    "                writer.writerow([\n",
    "                    row['Timestamp'],\n",
    "                    f'\"{row[\"Interface\"]}\"',\n",
    "                    f'\"{row[\"CAN_ID\"]}\"',\n",
    "                    f'\"{row[\"Payload\"]}\"',\n",
    "                    f\"{row['CAN_ID_Inter_Arrival']:.5f}\",\n",
    "                    int(row['CAN_ID_Window_Count']),\n",
    "                    f\"{row['Payload_Entropy']:.5f}\",\n",
    "                    f\"{row['Norm_Inter_Arrival']:.5f}\",\n",
    "                    f\"{row['Norm_Window_Count']:.5f}\",\n",
    "                    f\"{row['Norm_Payload_Entropy']:.5f}\",\n",
    "                    f\"{row['Norm_Payload_Decimal']:.10f}\",\n",
    "                    f\"{row['Suspension_Indicator']:.5f}\",\n",
    "                    int(row['Label'])\n",
    "                ])\n",
    "        print(f\"✅ Conversion complete! CSV saved to: {output_file_path}\")\n",
    "        if os.access(output_file_path, os.W_OK):\n",
    "            print(\"File is writable.\")\n",
    "        else:\n",
    "            print(\"Warning: File is read-only. Check permissions or OneDrive sync.\")\n",
    "    except PermissionError as e:\n",
    "        print(f\"PermissionError: Cannot write to '{output_file_path}'. {e}\")\n",
    "        print(\"Suggestions:\")\n",
    "        print(\"- Ensure the output file is not open in another application.\")\n",
    "        print(\"- Check write permissions for the directory.\")\n",
    "        print(\"- Run the script as Administrator.\")\n",
    "        print(\"- Pause OneDrive sync.\")\n",
    "        print(\"- Use a different output path (e.g., 'C:\\\\Temp\\\\can_bus_combined.csv').\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing output file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nLabel Counts:\")\n",
    "    print(df['Label'].value_counts())\n",
    "    print(\"\\nColumns:\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\nSample Rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nSuspension Attack Messages (first 5):\")\n",
    "    print(df[df['Label'] == 3][['Timestamp', 'CAN_ID', 'CAN_ID_Inter_Arrival', 'Suspension_Indicator', 'Label']].head())\n",
    "    print(\"\\nFuzzing Attack Messages (first 5):\")\n",
    "    print(df[df['Label'] == 2][['Timestamp', 'CAN_ID', 'Payload_Entropy', 'Label']].head())\n",
    "    print(\"\\nDoS Attack Messages (first 5):\")\n",
    "    print(df[df['Label'] == 1][['Timestamp', 'CAN_ID', 'CAN_ID_Window_Count', 'Label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Execute Processing\n",
    "\n",
    "Run the processing function with the specified input and output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input file with 386567 lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing lines: 100%|██████████| 386567/386567 [00:02<00:00, 180864.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 386567 messages into DataFrame.\n",
      "Debug: Total CAN_ID=2C6 messages: 13752\n",
      "Injected DoS attack: 40000 messages.\n",
      "Warning: Only 600 messages available for CAN_ID=18A for fuzzing.\n",
      "Added 1622 synthetic fuzzing messages.\n",
      "Injected Fuzzing attack: 2222 messages.\n",
      "Debug: Deleted 1000 CAN_ID=2C6 messages in Suspension period.\n",
      "After Suspension attack: 413121 messages remain.\n",
      "Computed CAN_ID_Inter_Arrival.\n",
      "Computing CAN_ID_Window_Count for 413121 messages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CAN_IDs: 100%|██████████| 56/56 [00:03<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: NaN in CAN_ID_Window_Count: 0\n",
      "Computed CAN_ID_Window_Count.\n",
      "Computed Payload_Entropy.\n",
      "Computed Payload_Decimal.\n",
      "Computed Norm_Payload_Decimal.\n",
      "Computed Norm_Payload_Entropy.\n",
      "Computing Suspension_Indicator for 413121 messages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing messages: 100%|██████████| 413121/413121 [09:06<00:00, 756.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Suspension_Indicator.\n",
      "Debug: CAN_ID=2C6 messages after suspension_end (1508687506.0): 2147\n",
      "Debug: First 5 CAN_ID=2C6 messages post-Suspension:\n",
      "           Timestamp  CAN_ID_Inter_Arrival  Suspension_Indicator  \\\n",
      "311157  1.508688e+09             20.022096              0.035714   \n",
      "311183  1.508688e+09              0.019225              0.035714   \n",
      "311211  1.508688e+09              0.019824              0.035714   \n",
      "311240  1.508688e+09              0.019994              0.035714   \n",
      "311267  1.508688e+09              0.020039              0.035714   \n",
      "\n",
      "        Payload_Entropy  \n",
      "311157         0.650022  \n",
      "311183         0.650022  \n",
      "311211         0.650022  \n",
      "311240         0.650022  \n",
      "311267         0.650022  \n",
      "Computed normal statistics.\n",
      "Normalizing features for 413121 messages...\n",
      "Computed normalized features.\n",
      "Warning: Only 2147 CAN_ID=2C6 messages available post-suspension.\n",
      "Added 75 synthetic suspension messages.\n",
      "Labeled 2222 Suspension messages.\n",
      "\n",
      "Feature Distributions by Label:\n",
      "Label 0 (Normal):\n",
      "       CAN_ID_Inter_Arrival  CAN_ID_Window_Count  Payload_Entropy  \\\n",
      "count         370916.000000        370916.000000    370916.000000   \n",
      "mean               0.040745           277.839716         1.910039   \n",
      "std                0.153754           234.075097         0.995535   \n",
      "min                0.000025             0.000000         0.000000   \n",
      "25%                0.010022            51.000000         1.000000   \n",
      "50%                0.019925           250.000000         2.321928   \n",
      "75%                0.049687           500.000000         2.750000   \n",
      "max               20.022096         19992.000000         3.000000   \n",
      "\n",
      "       Suspension_Indicator  \n",
      "count         370916.000000  \n",
      "mean               0.013794  \n",
      "std                0.043069  \n",
      "min                0.000000  \n",
      "25%                0.000000  \n",
      "50%                0.017857  \n",
      "75%                0.017857  \n",
      "max                0.946429  \n",
      "Label 1 (DoS):\n",
      "       CAN_ID_Inter_Arrival  CAN_ID_Window_Count  Payload_Entropy  \\\n",
      "count          39983.000000         39983.000000          39983.0   \n",
      "mean               0.000250         13964.268789              0.0   \n",
      "std                0.000049          7290.630861              0.0   \n",
      "min                0.000250             0.000000              0.0   \n",
      "25%                0.000250          7785.500000              0.0   \n",
      "50%                0.000250         18517.000000              0.0   \n",
      "75%                0.000250         19992.000000              0.0   \n",
      "max                0.010000         19992.000000              0.0   \n",
      "\n",
      "       Suspension_Indicator  \n",
      "count          39983.000000  \n",
      "mean               0.042071  \n",
      "std                0.185535  \n",
      "min                0.000000  \n",
      "25%                0.000000  \n",
      "50%                0.000000  \n",
      "75%                0.000000  \n",
      "max                0.910714  \n",
      "Label 2 (Fuzzing):\n",
      "       CAN_ID_Inter_Arrival  CAN_ID_Window_Count  Payload_Entropy  \\\n",
      "count           2222.000000          2222.000000      2222.000000   \n",
      "mean               0.002701          1200.861386         2.890058   \n",
      "std                0.001216           528.591904         0.166791   \n",
      "min                0.000007             0.000000         2.405639   \n",
      "25%                0.001695           817.250000         2.750000   \n",
      "50%                0.003432          1248.500000         3.000000   \n",
      "75%                0.003701          1684.750000         3.000000   \n",
      "max                0.003701          1852.000000         3.000000   \n",
      "\n",
      "       Suspension_Indicator  \n",
      "count           2222.000000  \n",
      "mean               0.011894  \n",
      "std                0.008424  \n",
      "min                0.000000  \n",
      "25%                0.000000  \n",
      "50%                0.017857  \n",
      "75%                0.017857  \n",
      "max                0.017857  \n",
      "Label 3 (Suspension):\n",
      "       CAN_ID_Inter_Arrival  CAN_ID_Window_Count  Payload_Entropy  \\\n",
      "count                  75.0                 75.0             75.0   \n",
      "mean                   10.0                  1.0              0.0   \n",
      "std                     0.0                  0.0              0.0   \n",
      "min                    10.0                  1.0              0.0   \n",
      "25%                    10.0                  1.0              0.0   \n",
      "50%                    10.0                  1.0              0.0   \n",
      "75%                    10.0                  1.0              0.0   \n",
      "max                    10.0                  1.0              0.0   \n",
      "\n",
      "       Suspension_Indicator  \n",
      "count                  75.0  \n",
      "mean                    1.0  \n",
      "std                     0.0  \n",
      "min                     1.0  \n",
      "25%                     1.0  \n",
      "50%                     1.0  \n",
      "75%                     1.0  \n",
      "max                     1.0  \n",
      "Writing 413196 rows to CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing CSV rows: 100%|██████████| 413196/413196 [00:57<00:00, 7245.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion complete! CSV saved to: C:\\Users\\pc\\OneDrive\\Bureau\\VS_code_Projects\\MLproject_Predictive_Maintenance_for_Vehicles_Using_CAN_Bus_Data\\dataSet\\processed\\generated.csv\n",
      "File is writable.\n",
      "\n",
      "Label Counts:\n",
      "Label\n",
      "0    370916\n",
      "1     39983\n",
      "2      2222\n",
      "3        75\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columns:\n",
      "['Timestamp', 'Interface', 'CAN_ID', 'Payload', 'CAN_ID_Inter_Arrival', 'CAN_ID_Window_Count', 'Payload_Entropy', 'Payload_Decimal', 'Norm_Payload_Decimal', 'Norm_Payload_Entropy', 'Suspension_Indicator', 'Norm_Inter_Arrival', 'Norm_Window_Count', 'Label']\n",
      "\n",
      "Sample Rows:\n",
      "      Timestamp Interface CAN_ID           Payload  CAN_ID_Inter_Arrival  \\\n",
      "0  1.508687e+09    slcan0    12E  C680027FD0FFFF00                  0.01   \n",
      "1  1.508687e+09    slcan0    090          1A000000                  0.01   \n",
      "2  1.508687e+09    slcan0    0C6  7512800A8008BAAC                  0.01   \n",
      "3  1.508687e+09    slcan0    242    0000FFEFFE000D                  0.01   \n",
      "4  1.508687e+09    slcan0    29C  00000000FFFFFFFF                  0.01   \n",
      "\n",
      "   CAN_ID_Window_Count  Payload_Entropy  Payload_Decimal  \\\n",
      "0                    1         2.750000     1.430344e+19   \n",
      "1                    1         0.811278     4.362076e+08   \n",
      "2                    1         2.750000     8.435946e+18   \n",
      "3                    1         2.128085     1.099243e+12   \n",
      "4                    1         1.000000     4.294967e+09   \n",
      "\n",
      "   Norm_Payload_Decimal  Norm_Payload_Entropy  Suspension_Indicator  \\\n",
      "0          7.753908e-01              0.343750                   0.0   \n",
      "1          2.364686e-11              0.101410                   0.0   \n",
      "2          4.573135e-01              0.343750                   0.0   \n",
      "3          5.959009e-08              0.266011                   0.0   \n",
      "4          2.328306e-10              0.125000                   0.0   \n",
      "\n",
      "   Norm_Inter_Arrival  Norm_Window_Count  Label  \n",
      "0            0.963624           0.002193      0  \n",
      "1            0.963624           0.002195      0  \n",
      "2            0.963623           0.002189      0  \n",
      "3            0.481793           0.004378      0  \n",
      "4            0.481829           0.004381      0  \n",
      "\n",
      "Suspension Attack Messages (first 5):\n",
      "           Timestamp CAN_ID  CAN_ID_Inter_Arrival  Suspension_Indicator  Label\n",
      "413121  1.508688e+09    2C6                  10.0                   1.0      3\n",
      "413122  1.508688e+09    2C6                  10.0                   1.0      3\n",
      "413123  1.508688e+09    2C6                  10.0                   1.0      3\n",
      "413124  1.508688e+09    2C6                  10.0                   1.0      3\n",
      "413125  1.508688e+09    2C6                  10.0                   1.0      3\n",
      "\n",
      "Fuzzing Attack Messages (first 5):\n",
      "           Timestamp CAN_ID  Payload_Entropy  Label\n",
      "316749  1.508688e+09    18A             2.75      2\n",
      "316751  1.508688e+09    18A             2.75      2\n",
      "316756  1.508688e+09    18A             3.00      2\n",
      "316760  1.508688e+09    18A             2.75      2\n",
      "316763  1.508688e+09    18A             3.00      2\n",
      "\n",
      "DoS Attack Messages (first 5):\n",
      "           Timestamp CAN_ID  CAN_ID_Window_Count  Label\n",
      "332414  1.508688e+09    000                    1      1\n",
      "332415  1.508688e+09    000                    2      1\n",
      "332416  1.508688e+09    000                    3      1\n",
      "332417  1.508688e+09    000                    4      1\n",
      "332418  1.508688e+09    000                    5      1\n"
     ]
    }
   ],
   "source": [
    "# Define input and output paths\n",
    "input_file_path = r\"C:\\Users\\pc\\OneDrive\\Bureau\\VS_code_Projects\\MLproject_Predictive_Maintenance_for_Vehicles_Using_CAN_Bus_Data\\dataSet\\raw\\full_data_capture.log\"\n",
    "output_file_path = r\"C:\\Users\\pc\\OneDrive\\Bureau\\VS_code_Projects\\MLproject_Predictive_Maintenance_for_Vehicles_Using_CAN_Bus_Data\\dataSet\\processed\\generated.csv\"\n",
    "\n",
    "# Run processing\n",
    "convert_can_log_to_csv(input_file_path, output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
